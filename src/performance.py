"""
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

å¤§è¦æ¨¡ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†æœ€é©åŒ–ã€ãƒ¡ãƒ¢ãƒªç®¡ç†ã€ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import time
import hashlib
import pickle
from pathlib import Path
from typing import Any, Optional, Dict, Callable
from functools import wraps
import psutil
import gc


class PerformanceMonitor:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.metrics: Dict[str, Dict[str, Any]] = {}
        self.start_times: Dict[str, float] = {}
    
    def start_operation(self, operation_name: str):
        """æ“ä½œã®é–‹å§‹ã‚’è¨˜éŒ²"""
        self.start_times[operation_name] = time.time()
    
    def end_operation(self, operation_name: str) -> float:
        """
        æ“ä½œã®çµ‚äº†ã‚’è¨˜éŒ²
        
        Returns:
            å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰
        """
        if operation_name not in self.start_times:
            return 0.0
        
        elapsed = time.time() - self.start_times[operation_name]
        
        if operation_name not in self.metrics:
            self.metrics[operation_name] = {
                'count': 0,
                'total_time': 0.0,
                'min_time': float('inf'),
                'max_time': 0.0
            }
        
        metrics = self.metrics[operation_name]
        metrics['count'] += 1
        metrics['total_time'] += elapsed
        metrics['min_time'] = min(metrics['min_time'], elapsed)
        metrics['max_time'] = max(metrics['max_time'], elapsed)
        
        del self.start_times[operation_name]
        return elapsed
    
    def get_metrics(self, operation_name: str) -> Optional[Dict[str, Any]]:
        """æ“ä½œã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—"""
        if operation_name not in self.metrics:
            return None
        
        metrics = self.metrics[operation_name].copy()
        if metrics['count'] > 0:
            metrics['avg_time'] = metrics['total_time'] / metrics['count']
        
        return metrics
    
    def get_all_metrics(self) -> Dict[str, Dict[str, Any]]:
        """ã™ã¹ã¦ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—"""
        result = {}
        for name in self.metrics:
            result[name] = self.get_metrics(name)
        return result
    
    def print_summary(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        print("\n" + "="*70)
        print("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹")
        print("="*70)
        
        for operation_name, metrics in self.get_all_metrics().items():
            print(f"\n{operation_name}:")
            print(f"  å®Ÿè¡Œå›æ•°: {metrics['count']}")
            print(f"  åˆè¨ˆæ™‚é–“: {metrics['total_time']:.3f}ç§’")
            print(f"  å¹³å‡æ™‚é–“: {metrics['avg_time']:.3f}ç§’")
            print(f"  æœ€å°æ™‚é–“: {metrics['min_time']:.3f}ç§’")
            print(f"  æœ€å¤§æ™‚é–“: {metrics['max_time']:.3f}ç§’")
        
        print("="*70)
    
    def reset(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.metrics.clear()
        self.start_times.clear()


class MemoryMonitor:
    """ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.process = psutil.Process()
        self.initial_memory = self.get_memory_usage()
    
    def get_memory_usage(self) -> float:
        """
        ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—ï¼ˆMBå˜ä½ï¼‰
        
        Returns:
            ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆMBï¼‰
        """
        return self.process.memory_info().rss / 1024 / 1024
    
    def get_memory_increase(self) -> float:
        """
        åˆæœŸçŠ¶æ…‹ã‹ã‚‰ã®ãƒ¡ãƒ¢ãƒªå¢—åŠ é‡ã‚’å–å¾—ï¼ˆMBå˜ä½ï¼‰
        
        Returns:
            ãƒ¡ãƒ¢ãƒªå¢—åŠ é‡ï¼ˆMBï¼‰
        """
        return self.get_memory_usage() - self.initial_memory
    
    def print_memory_status(self):
        """ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹ã‚’è¡¨ç¤º"""
        current = self.get_memory_usage()
        increase = self.get_memory_increase()
        
        print(f"\nãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³:")
        print(f"  ç¾åœ¨: {current:.2f} MB")
        print(f"  å¢—åŠ é‡: {increase:.2f} MB")
        print(f"  åˆæœŸ: {self.initial_memory:.2f} MB")
    
    def check_memory_limit(self, limit_mb: float) -> bool:
        """
        ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒåˆ¶é™ã‚’è¶…ãˆã¦ã„ã‚‹ã‹ç¢ºèª
        
        Args:
            limit_mb: ãƒ¡ãƒ¢ãƒªåˆ¶é™ï¼ˆMBï¼‰
        
        Returns:
            åˆ¶é™ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆTrue
        """
        return self.get_memory_usage() > limit_mb
    
    def force_garbage_collection(self):
        """å¼·åˆ¶çš„ã«ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        gc.collect()


class ResultCache:
    """çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, cache_dir: str = ".cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.enabled = True
    
    def _get_cache_key(self, *args, **kwargs) -> str:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        key_data = str((args, sorted(kwargs.items())))
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def _get_cache_path(self, cache_key: str) -> Path:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—"""
        return self.cache_dir / f"{cache_key}.cache"
    
    def get(self, *args, **kwargs) -> Optional[Any]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—"""
        if not self.enabled:
            return None
        
        cache_key = self._get_cache_key(*args, **kwargs)
        cache_path = self._get_cache_path(cache_key)
        
        if cache_path.exists():
            try:
                with open(cache_path, 'rb') as f:
                    return pickle.load(f)
            except Exception:
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆã¯å‰Šé™¤
                cache_path.unlink(missing_ok=True)
        
        return None
    
    def set(self, result: Any, *args, **kwargs):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
        if not self.enabled:
            return
        
        cache_key = self._get_cache_key(*args, **kwargs)
        cache_path = self._get_cache_path(cache_key)
        
        try:
            with open(cache_path, 'wb') as f:
                pickle.dump(result, f)
        except Exception:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¿å­˜ã«å¤±æ•—ã—ã¦ã‚‚ç¶™ç¶š
            pass
    
    def clear(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        for cache_file in self.cache_dir.glob("*.cache"):
            cache_file.unlink(missing_ok=True)
    
    def disable(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡åŠ¹åŒ–"""
        self.enabled = False
    
    def enable(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æœ‰åŠ¹åŒ–"""
        self.enabled = True


def monitor_performance(operation_name: str):
    """
    ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼
    
    Args:
        operation_name: æ“ä½œå
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼ã‚’å–å¾—ï¼ˆç¬¬ä¸€å¼•æ•°ãŒselfã®å ´åˆï¼‰
            monitor = None
            if args and hasattr(args[0], 'performance_monitor'):
                monitor = args[0].performance_monitor
            
            if monitor:
                monitor.start_operation(operation_name)
            
            result = func(*args, **kwargs)
            
            if monitor:
                elapsed = monitor.end_operation(operation_name)
                print(f"  â±ï¸  {operation_name}: {elapsed:.3f}ç§’")
            
            return result
        
        return wrapper
    
    return decorator


def check_memory(limit_mb: float = 1000):
    """
    ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼
    
    Args:
        limit_mb: ãƒ¡ãƒ¢ãƒªåˆ¶é™ï¼ˆMBï¼‰
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ãƒ¡ãƒ¢ãƒªãƒ¢ãƒ‹ã‚¿ãƒ¼ã‚’å–å¾—
            monitor = None
            if args and hasattr(args[0], 'memory_monitor'):
                monitor = args[0].memory_monitor
            
            if monitor and monitor.check_memory_limit(limit_mb):
                print(f"âš ï¸  ãƒ¡ãƒ¢ãƒªåˆ¶é™ã«è¿‘ã¥ã„ã¦ã„ã¾ã™: {monitor.get_memory_usage():.2f} MB")
                monitor.force_garbage_collection()
            
            result = func(*args, **kwargs)
            
            return result
        
        return wrapper
    
    return decorator


def cache_result(cache: Optional[ResultCache] = None):
    """
    çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼
    
    Args:
        cache: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å–å¾—
            result_cache = cache
            if result_cache is None and args and hasattr(args[0], 'result_cache'):
                result_cache = args[0].result_cache
            
            if result_cache:
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
                cached = result_cache.get(*args, **kwargs)
                if cached is not None:
                    print(f"  ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {func.__name__}")
                    return cached
            
            # å®Ÿéš›ã®å‡¦ç†ã‚’å®Ÿè¡Œ
            result = func(*args, **kwargs)
            
            # çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            if result_cache:
                result_cache.set(result, *args, **kwargs)
            
            return result
        
        return wrapper
    
    return decorator


class ChunkedFileReader:
    """å¤§è¦æ¨¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ£ãƒ³ã‚¯å˜ä½ã§èª­ã¿è¾¼ã‚€ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, chunk_size: int = 1024 * 1024):
        """
        åˆæœŸåŒ–
        
        Args:
            chunk_size: ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ1MBï¼‰
        """
        self.chunk_size = chunk_size
    
    def read_chunks(self, file_path: str):
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ£ãƒ³ã‚¯å˜ä½ã§èª­ã¿è¾¼ã‚€
        
        Args:
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
        Yields:
            ãƒãƒ£ãƒ³ã‚¯ï¼ˆæ–‡å­—åˆ—ï¼‰
        """
        with open(file_path, 'r', encoding='utf-8') as f:
            while True:
                chunk = f.read(self.chunk_size)
                if not chunk:
                    break
                yield chunk
    
    def process_large_file(
        self,
        file_path: str,
        processor: Callable[[str], Any],
        combine: Callable[[list], Any]
    ) -> Any:
        """
        å¤§è¦æ¨¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ£ãƒ³ã‚¯å˜ä½ã§å‡¦ç†
        
        Args:
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            processor: ãƒãƒ£ãƒ³ã‚¯å‡¦ç†é–¢æ•°
            combine: çµæœçµ±åˆé–¢æ•°
        
        Returns:
            å‡¦ç†çµæœ
        """
        results = []
        
        for chunk in self.read_chunks(file_path):
            result = processor(chunk)
            results.append(result)
        
        return combine(results)


class OptimizationConfig:
    """æœ€é©åŒ–è¨­å®š"""
    
    def __init__(
        self,
        enable_cache: bool = True,
        enable_parallel: bool = True,
        max_workers: int = 4,
        memory_limit_mb: float = 1000,
        chunk_size: int = 1024 * 1024
    ):
        self.enable_cache = enable_cache
        self.enable_parallel = enable_parallel
        self.max_workers = max_workers
        self.memory_limit_mb = memory_limit_mb
        self.chunk_size = chunk_size
    
    def to_dict(self) -> Dict[str, Any]:
        """è¾æ›¸ã«å¤‰æ›"""
        return {
            'enable_cache': self.enable_cache,
            'enable_parallel': self.enable_parallel,
            'max_workers': self.max_workers,
            'memory_limit_mb': self.memory_limit_mb,
            'chunk_size': self.chunk_size
        }


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_global_performance_monitor: Optional[PerformanceMonitor] = None
_global_memory_monitor: Optional[MemoryMonitor] = None
_global_result_cache: Optional[ResultCache] = None


def get_performance_monitor() -> PerformanceMonitor:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼ã‚’å–å¾—"""
    global _global_performance_monitor
    if _global_performance_monitor is None:
        _global_performance_monitor = PerformanceMonitor()
    return _global_performance_monitor


def get_memory_monitor() -> MemoryMonitor:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¡ãƒ¢ãƒªãƒ¢ãƒ‹ã‚¿ãƒ¼ã‚’å–å¾—"""
    global _global_memory_monitor
    if _global_memory_monitor is None:
        _global_memory_monitor = MemoryMonitor()
    return _global_memory_monitor


def get_result_cache() -> ResultCache:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å–å¾—"""
    global _global_result_cache
    if _global_result_cache is None:
        _global_result_cache = ResultCache()
    return _global_result_cache
